var documenterSearchIndex = {"docs":
[{"location":"algorithms/hyperopt/#Multi-start-optimization","page":"Multi-start optimization","title":"Multi-start optimization","text":"","category":"section"},{"location":"algorithms/hyperopt/#Description","page":"Multi-start optimization","title":"Description","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"Hyperopt.jl is a Julia library that implements a number of hyperparameter optimization algorithms which can be used to optimize the starting point of the optimization.","category":"page"},{"location":"algorithms/hyperopt/#Quick-start","page":"Multi-start optimization","title":"Quick start","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using Hyperopt.","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"import Hyperopt\n\nalg = HyperoptAlg(IpoptAlg())\noptions = HyperoptOptions(sub_options = IpoptOptions(), sampler = GPSampler())\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"Hyperopt is an optional dependency of Nonconvex so you need to import it in order to use it. HyperoptAlg can wrap any other algorithm in Nonconvex, e.g. IpoptAlg(). When the algorithm is a HyperoptAlg, the options keyword argument must of type HyperoptOptions. For more on the options available see below.","category":"page"},{"location":"algorithms/hyperopt/#Construct-an-instance","page":"Multi-start optimization","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"To construct an instance of the Hyperopt + Ipopt algorithm, use:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"alg = HyperoptAlg(IpoptAlg())","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"HyperoptAlg can wrap any other algorithm in Nonconvex, e.g. NLoptAlg(:LD_MMA) or AugLag().","category":"page"},{"location":"algorithms/hyperopt/#Options","page":"Multi-start optimization","title":"Options","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"The options keyword argument to the optimize function shown above must be an instance of the HyperoptOptions struct when the algorihm is a HyperoptAlg. To specify options, use keyword arguments in the constructor of HyperoptOptions. The sampler keyword argument determines the sampling algorithm used to propose new starting points in the multi-start procedure. The sub_options keyword argument can be used to pass in the options for the sub-optimizer. There are 2 different ways to pass the sub-options depending on the sampler type.","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"The sampler argument can be of type:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"RandomSampler\nLHSampler\nCLHSampler\nGPSampler\nHyperband","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"When optimizing the starting point, the upper and lower bounds on the initial solution must be finite, or finite bounds must be passed in to the options constructor. All the options that can be passed to the HyperoptOptions constructor are listed below:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"HyperoptOptions","category":"page"},{"location":"algorithms/hyperopt/#Nonconvex.HyperoptOptions","page":"Multi-start optimization","title":"Nonconvex.HyperoptOptions","text":"HyperoptOptions: options performing starting point optimization using Hyperopt.jl\n\nsub_options: options for the sub-optimizer.\nlb: Lower bound of starting point, if don't specify it, the default value will be nothing,            then will end up be replaced by the lower bound of optimization problem.\nub: Upper bound of starting point, same as above. \nsearchspace_size::Integer: How many potential starting points we generate.\niters::Integer: Among all generated potential starting points, how many of them will be evaluated. \nsampler::Hyperopt.Sampler: An instance of 'Hyperopt.Sampler', which decides search algorithm. \nctol: infeasibility tolerance for accepting a solution as feasible\nkeep_all: if true, all the solutions of the sub-problems will be saved\n\n\n\n\n\n","category":"type"},{"location":"algorithms/hyperopt/#Sampler-choice","page":"Multi-start optimization","title":"Sampler choice","text":"","category":"section"},{"location":"algorithms/hyperopt/#RandomSampler,-LHSampler,-CLHSampler-and-GPSampler","page":"Multi-start optimization","title":"RandomSampler, LHSampler, CLHSampler and GPSampler","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"All the sampler constructors are functions defined in Nonconvex wrapping the Hyperopt alternatives to define defaults. For GPSampler, Hyperopt.Min is always used by default in Nonconvex so you should not pass this argument. All the other arguments that can be passed to the sampler constructor can be found in the Hyperopt documentation. Example:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"options = HyperoptOptions(sub_options = IpoptOptions(), sampler = GPSampler())","category":"page"},{"location":"algorithms/hyperopt/#Hyperband","page":"Multi-start optimization","title":"Hyperband","text":"","category":"section"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"The Hyperband algorithm in Hyperopt requires a different way to pass in the sub-options. The Hyperband algorithm tries to optimize the allocation of resources. The sub_options argument must be a function with input as the \"resources\" and output as the sub-solver options. The Hyperband constructor accepts 3 arguments:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"The maximum resources R\nη which roughly determines the proportion of trials discarded between each round of successive halving\ninner which specifies an inner sampler of type RandomSampler, LHSampler or CLHSampler.","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"Example:","category":"page"},{"location":"algorithms/hyperopt/","page":"Multi-start optimization","title":"Multi-start optimization","text":"options = HyperoptOptions(\n    sub_options = max_iter -> IpoptOptions(max_iter = max_iter), \n    sampler = Hyperband(R=100, η=3, inner=RandomSampler()),\n)","category":"page"},{"location":"algorithms/minlp/#Mixed-integer-nonlinear-programming-(MINLP)","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"","category":"section"},{"location":"algorithms/minlp/#Description","page":"Mixed integer nonlinear programming (MINLP)","title":"Description","text":"","category":"section"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"There are 2 MINLP solvers available in Nonconvex:","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"Juniper.jl with Ipopt.jl as a sub-solver.\nPavito.jl with Ipopt.jl and Cbc.jl as sub-solvers.","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"These rely on local nonlinear programming solvers and a branch and bound procedure to find a locally optimal solution that satisfies the integerality constraints.","category":"page"},{"location":"algorithms/minlp/#Juniper-Ipopt","page":"Mixed integer nonlinear programming (MINLP)","title":"Juniper + Ipopt","text":"","category":"section"},{"location":"algorithms/minlp/#Quick-start","page":"Mixed integer nonlinear programming (MINLP)","title":"Quick start","text":"","category":"section"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using Juniper and Ipopt.","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"import Juniper\n\nalg = JuniperIpoptAlg()\noptions = JuniperIpoptOptions()\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"Juniper is an optional dependency of Nonconvex, so you need to load it in order to use it. Note that the integer constraints must be specified when defining variables. See the problem definition documentation for more details.","category":"page"},{"location":"algorithms/minlp/#Construct-an-instance","page":"Mixed integer nonlinear programming (MINLP)","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"To construct an instance of the Juniper + Ipopt algorithm, use:","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"alg = JuniperIpoptAlg()","category":"page"},{"location":"algorithms/minlp/#Options","page":"Mixed integer nonlinear programming (MINLP)","title":"Options","text":"","category":"section"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"The options keyword argument to the optimize function shown above must be an instance of the JuniperIpoptOptions struct when the algorihm is a JuniperIpoptAlg. To specify options use, keyword arguments in the constructor of JuniperIpoptOptions, e.g:","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"options = JuniperIpoptOptions(first_order = false, linear_constraints = true, subsolver_options = IpoptOptions(), atol = 1e-4)","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"There are 3 important and special options you can pass to the optimizer:","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"first_order: true by default. When first_order is true, the first order Ipopt algorithm will be used. And when it is false, the second order Ipopt algorithm will be used.\nlinear_constraints: false by default. When linear_constraints is true, the Jacobian of the constraints will be computed and sparsified once at the beginning. When it is false, dense Jacobians will be computed in every iteration.\nsubsolver_options: an instance of IpoptOptions to be used in the Ipopt sub-solver.","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"All the other options to Juniper can be found in the Juniper documentation.","category":"page"},{"location":"algorithms/minlp/#Pavito-Ipopt-Cbc","page":"Mixed integer nonlinear programming (MINLP)","title":"Pavito + Ipopt + Cbc","text":"","category":"section"},{"location":"algorithms/minlp/#Quick-start-2","page":"Mixed integer nonlinear programming (MINLP)","title":"Quick start","text":"","category":"section"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using Juniper and Ipopt.","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"import Pavito\n\nalg = PavitoIpoptCbcAlg()\noptions = PavitoIpoptCbcOptions()\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"Pavito is an optional dependency of Nonconvex, so you need to load it in order to use it. Note that the integer constraints must be specified when defining variables. See the problem definition documentation for more details.","category":"page"},{"location":"algorithms/minlp/#Construct-an-instance-2","page":"Mixed integer nonlinear programming (MINLP)","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"To construct an instance of the Pavito + Ipopt + Cbc algorithm, use:","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"alg = PavitoIpoptCbcAlg()","category":"page"},{"location":"algorithms/minlp/#Options-2","page":"Mixed integer nonlinear programming (MINLP)","title":"Options","text":"","category":"section"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"The options keyword argument to the optimize function shown above must be an instance of PavitoIpoptCbcOptions struct when the algorithm is a PavitoIpoptCbcAlg. To specify options, use keyword arguments in the constructor of JuniperIpoptOptions or PavitoIpoptCbcOptions, e.g:","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"options = PavitoIpoptCbcOptions(first_order = false, subsolver_options = IpoptOptions(), timeout = 120.0)","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"There are 2 important and special options you can pass to the optimizer:","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"first_order: true by default. When first_order is true, the first order Ipopt algorithm will be used. And when it is false, the second order Ipopt algorithm will be used.\nsubsolver_options: an instance of IpoptOptions to be used in the Ipopt sub-solver.","category":"page"},{"location":"algorithms/minlp/","page":"Mixed integer nonlinear programming (MINLP)","title":"Mixed integer nonlinear programming (MINLP)","text":"All the other options to Pavito can be found in the Pavito documentation.","category":"page"},{"location":"algorithms/auglag/#Augmented-Lagrangian-algorithm","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"","category":"section"},{"location":"algorithms/auglag/#Description","page":"Augmented Lagrangian algorithm","title":"Description","text":"","category":"section"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"Percival.jl is a pure Julia implementation of the augmented Lagrangian algorithm. Both first and second order versions of the algorithm are available.","category":"page"},{"location":"algorithms/auglag/#Quick-start","page":"Augmented Lagrangian algorithm","title":"Quick start","text":"","category":"section"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using Percival.","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"import Percival\n\nalg = AugLag()\noptions = AugLagOptions()\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"Percival is an optional dependency of Nonconvex so you need to import it in order to use it.","category":"page"},{"location":"algorithms/auglag/#Construct-an-instance","page":"Augmented Lagrangian algorithm","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"To construct an instance of the Ipopt algorithm, use:","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"alg = AugAlg()","category":"page"},{"location":"algorithms/auglag/#Options","page":"Augmented Lagrangian algorithm","title":"Options","text":"","category":"section"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"The options keyword argument to the optimize function shown above must be an instance of the AugLagOptions struct when the algorihm is an AugLag. To specify options use keyword arguments in the constructor of AugLagOptions, e.g:","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"options = AugLagOptions(first_order = false, rtol = 1e-4)","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"The most important option is first_order which is true by default. When first_order is true, the first order augmented Lagrangian algorithm will be used. And when it is false, the second order augmented Lagrangian algorithm will be used. Other arguments include:","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"atol: absolute tolerance in the subproblem optimizer\nrtol: relative tolerance in the subproblem optimizer\nctol: absolute feasibility tolerance\nmax_iter: maximum number of iterations\nmax_time: maximum time in seconds\nmax_eval: maximum number of function evaluations","category":"page"},{"location":"algorithms/auglag/","page":"Augmented Lagrangian algorithm","title":"Augmented Lagrangian algorithm","text":"When using the first order augmented Lagrangian and a block constraint (i.e. a constraint function that returns a vector), the use of reverse-mode AD will only require calling the adjoint operator of the block constraint function in order to compute the gradient of the augmented Lagrangian. This is particularly suitable for constraint functions whose Jacobians are expensive but the adjoint operator is relatively inexpensive.","category":"page"},{"location":"algorithms/ipopt/#Ipopt","page":"Ipopt","title":"Ipopt","text":"","category":"section"},{"location":"algorithms/ipopt/#Description","page":"Ipopt","title":"Description","text":"","category":"section"},{"location":"algorithms/ipopt/","page":"Ipopt","title":"Ipopt","text":"Ipopt is a well known interior point optimizer developed and maintained by COIN-OR. The Julia wrapper of Ipopt is Ipopt.jl. Nonconvex allows the use of Ipopt.jl using the IpoptAlg algorithm struct. Ipopt can be used as a second order optimizer using the Hessian of the Lagrangian. Alternatively, an l-BFGS approximation of the Hessian can be used instead turning Ipopt into a first order optimizer tha only requires the gradient of the Lagrangian.","category":"page"},{"location":"algorithms/ipopt/#Quick-start","page":"Ipopt","title":"Quick start","text":"","category":"section"},{"location":"algorithms/ipopt/","page":"Ipopt","title":"Ipopt","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using Ipopt.","category":"page"},{"location":"algorithms/ipopt/","page":"Ipopt","title":"Ipopt","text":"alg = IpoptAlg()\noptions = IpoptOptions()\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/ipopt/#Construct-an-instance","page":"Ipopt","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/ipopt/","page":"Ipopt","title":"Ipopt","text":"To construct an instance of the Ipopt algorithm, use:","category":"page"},{"location":"algorithms/ipopt/","page":"Ipopt","title":"Ipopt","text":"alg = IpoptAlg()","category":"page"},{"location":"algorithms/ipopt/#Options","page":"Ipopt","title":"Options","text":"","category":"section"},{"location":"algorithms/ipopt/","page":"Ipopt","title":"Ipopt","text":"The options keyword argument to the optimize function shown above must be an instance of the IpoptOptions struct when the algorihm is an IpoptAlg. To specify options use keyword arguments in the constructor of IpoptOptions, e.g:","category":"page"},{"location":"algorithms/ipopt/","page":"Ipopt","title":"Ipopt","text":"options = IpoptOptions(first_order = false, tol = 1e-4)","category":"page"},{"location":"algorithms/ipopt/","page":"Ipopt","title":"Ipopt","text":"There are 2 important and special options:","category":"page"},{"location":"algorithms/ipopt/","page":"Ipopt","title":"Ipopt","text":"first_order: true by default. When first_order is true, the first order Ipopt algorithm will be used. And when it is false, the second order Ipopt algorithm will be used.\nlinear_constraints:  false by default. When linear_constraints is true, the Jacobian of the constraints will be computed and sparsified once at the beginning. When it is false, dense Jacobians will be computed in every iteration.","category":"page"},{"location":"algorithms/ipopt/","page":"Ipopt","title":"Ipopt","text":"All the other options that can be set can be found on the Ipopt options section of Ipopt's documentation.","category":"page"},{"location":"algorithms/mts/#Multiple-Trajectory-Search-(MTS)","page":"Multiple Trajectory Search (MTS)","title":"Multiple Trajectory Search (MTS)","text":"","category":"section"},{"location":"algorithms/mts/#Description","page":"Multiple Trajectory Search (MTS)","title":"Description","text":"","category":"section"},{"location":"algorithms/mts/","page":"Multiple Trajectory Search (MTS)","title":"Multiple Trajectory Search (MTS)","text":"MTS: Multiple Trajectory Search for Large Scale Global Optimization, is a derivative-free heuristic optimization method presented in paper (Lin-Yu Tseng and Chun Chen, 2008)[https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/EAMHCO/contributionsCEC08/tseng08mts.pdf].  The main algorihtm MTS contains three subalgorithms localsearch1, localsearch2 and localsearch3. This module implelents all the optimization methods in paper. People often use entire MTS or only localsearch1 subalgorithm to optimize functions, and generally nobody use localsearch2 or localsearch3 independently. Therefore, the module only exports MTS and localsearch1.","category":"page"},{"location":"algorithms/mts/#Quick-start","page":"Multiple Trajectory Search (MTS)","title":"Quick start","text":"","category":"section"},{"location":"algorithms/mts/","page":"Multiple Trajectory Search (MTS)","title":"Multiple Trajectory Search (MTS)","text":"Using default MTSOptions(). MTS is used for optimization. ","category":"page"},{"location":"algorithms/mts/","page":"Multiple Trajectory Search (MTS)","title":"Multiple Trajectory Search (MTS)","text":"LS1_options = MTSOptions()\nm = Model(f)\nlb = [0, 0]\nub = [5, 5]\n# Must have a box constraint. And (in)equality constraints are not supported for MTS methods.\naddvar!(m, lb, ub)\nresult = optimize(model, alg, x0, options = options","category":"page"},{"location":"algorithms/mts/#Options","page":"Multiple Trajectory Search (MTS)","title":"Options","text":"","category":"section"},{"location":"algorithms/mts/","page":"Multiple Trajectory Search (MTS)","title":"Multiple Trajectory Search (MTS)","text":"You can choose which algorithm to use by spycifying option.method. Avaliable list is [MTS (default), localsearch1, Nonconvex.localsearch2 (not recommend), Nonconvex.localsearch3 (not recommend)].","category":"page"},{"location":"algorithms/mts/","page":"Multiple Trajectory Search (MTS)","title":"Multiple Trajectory Search (MTS)","text":"LS1_options = MTSOptions(method=localsearch1)\nm = Model(f))\nlb = [0, 0]\nub = [5, 5]\n# Must have a box constraint. And (in)equality constraints are not supported in MTS methods.\naddvar!(m, lb, ub)\nresult = optimize(model, alg, x0, options = options","category":"page"},{"location":"problem/#Problem-definition","page":"Problem definition","title":"Problem definition","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"There are 3 ways to define a model in Nonconvex.jl:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"Model which assumes all the variables are indexed by an integer index starting from 1. The decision variables are therefore a vector.\nDictModel which assumes each variable has a name. The decision variables are stored in an OrderedDict, an ordered dictionary data structure.\nStart from JuMP.Model and convert it to DictModel. This is convenient to make use of JuMP's user-friendly macros for variable and linear expression, objective or constraint definitions.","category":"page"},{"location":"problem/#Working-with-Model","page":"Problem definition","title":"Working with Model","text":"","category":"section"},{"location":"problem/#Model-definition","page":"Problem definition","title":"Model definition","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To define an empty model, run:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"model =  Model()","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To specify an objective function obj when creating the model, run:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"model = Model(obj)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"where obj is a function that takes a single vector argument.","category":"page"},{"location":"problem/#Variable-definition","page":"Problem definition","title":"Variable definition","text":"","category":"section"},{"location":"problem/#Add-a-single-variable","page":"Problem definition","title":"Add a single variable","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To add a new variable to a Model with lower and upper bounds lb and ub respectively, use:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"addvar!(model, lb, ub)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"The variables added will be stacked on top of each other with a linear integer index. The lower and upper bounds for each variable don't have to be numbers, they can be:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"Dictionaries\nStructs\nTuples\nNamedTuples\nNested data structures","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"However, the values input cannot be vectors. A vector input has a different interpretation. See the next section.","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"The types of the lower and upper bounds of each variable must be the same and this type will be assumed to be the type of the decision variable. Different variables can have different types though. Vectorization and de-vectorization are handled automatically by Nonconvex.","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To specify an initial value, use the init keyword argument. To add an integer constraint on the variable, use the integer keyword argument. For example:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"addvar!(model, 0.0, 10.0, init = 1.0, integer = true)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"init must have the same type as the lower and upper bounds.","category":"page"},{"location":"problem/#Add-multiple-variables","page":"Problem definition","title":"Add multiple variables","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To add multiple variables simultaneously, pass in a vector of values for the bounds and optionally for the init and integer keyword arguments.","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"addvar!(model, [0.0, 0.0], [10.0, 10.0], init = [1.0, 1.0], integer = [true, false])","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"The elements of the vector can be:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"Vectors or arrays in general\nDictionaries\nStructs\nTuples\nNamedTuples\nNested data structures","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"Note that the use of vectors as elements is allowed. Similarly, the types of the lower and upper bounds and the initial values must be the same.","category":"page"},{"location":"problem/#Objective-definition","page":"Problem definition","title":"Objective definition","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To specify an objective function after creating the model, use:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"set_objective!(model, obj)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"where obj is a function that takes a single vector argument. The vector input to obj will be of the same structure, shape and types as the initial solution, lower bound and upper bound vector.","category":"page"},{"location":"problem/#Inequality-constraint-definition","page":"Problem definition","title":"Inequality constraint definition","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To define an inequality constraint f(x) <= 0, where f is a Julia function that accepts a single input vector, use:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"add_ineq_constraint!(model, f)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"The vector input to f will be of the same structure, shape and types as the initial solution, lower bound and upper bound vector. The function f can return:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"A number, in which case the constraint will be f(x) <= 0\nA vector or array of numbers, in which case the constraint will be applied element-wise f(x) .<= 0.\nAn arbitrary container or data structure, in which case the output will be vectorized first and the constraint will be applied element-wise on the vectorized output.","category":"page"},{"location":"problem/#Equality-constraint-definition","page":"Problem definition","title":"Equality constraint definition","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To define an inequality constraint f(x) == 0, where f is a Julia function that accepts a single input vector, use:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"add_eq_constraint!(model, f)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"The vector input to f will be of the same structure, shape and types as the initial solution, lower bound and upper bound vector. The function f can return:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"A number, in which case the constraint will be f(x) == 0\nA vector or array of numbers, in which case the constraint will be applied element-wise f(x) .== 0.\nAn arbitrary container or data structure, in which case the output will be vectorized first and the constraint will be applied element-wise on the vectorized output.","category":"page"},{"location":"problem/#Working-with-DictModel","page":"Problem definition","title":"Working with DictModel","text":"","category":"section"},{"location":"problem/#Model-definition-2","page":"Problem definition","title":"Model definition","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"There are 2 ways to define a DictModel. The direct method is:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"model = DictModel()","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To pass an objective function while constructing the model, use:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"model = DictModel(obj)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"where obj is a function that takes a single OrderedDict argument.","category":"page"},{"location":"problem/#JuMP-model-to-Nonconvex-DictModel","page":"Problem definition","title":"JuMP model to Nonconvex DictModel","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"JuMP.jl has an excellent API for defining variables and linear constraints. Using JuMP makes it straightforward to copy a set of linear constraints and variable definitions from a paper. In Nonconvex, you can start with a JuMP model, define variables and constraints using JuMP's API then convert it to a DictModel. For example:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"jump_model = JuMP.Model()\n@variable jump_model 0 <= x[i=1:3] <= 1\n@constraint jump_model sum(x) <= 1\nmodel = DictModel(jump_model)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"The objective can also be defined either using JuMP or Nonconvex. Once you convert the JuMP model to a Nonconvex model, you can go ahead and define more variables and constraints and/or set the objective in Nonconvex.","category":"page"},{"location":"problem/#Variable-definition-2","page":"Problem definition","title":"Variable definition","text":"","category":"section"},{"location":"problem/#Add-a-single-variable-2","page":"Problem definition","title":"Add a single variable","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"Each variable in a DictModel has a name which can be a symbol or string. Each named variable can have an arbitrary type, e.g:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"Vectors or arrays in general\nDictionaries\nStructs\nTuples\nNamedTuples\nNested data structures","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"Vectorization and de-vectorization are handled automatically by Nonconvex.","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To add a new named variable to a DictModel with a name :a and lower and upper bounds lb and ub respectively, use:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"addvar!(model, :a, lb, ub)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"Similar to Model, optional keyword arguments init and integer can be set, and the types of the initial value, lb and ub must be the same.","category":"page"},{"location":"problem/#Add-multiple-variables-2","page":"Problem definition","title":"Add multiple variables","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"There is no way to add multiple variables simultaneously to a DictModel however a single named variable that's a vector can be added.","category":"page"},{"location":"problem/#Objective-definition-2","page":"Problem definition","title":"Objective definition","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To specify an objective function after creating the model, use:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"set_objective!(model, obj)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"where obj is a function that takes a single OrderedDict argument. The OrderedDict input to obj will be of the same structure, shape and types as the OrderedDict initial solution, lower bounds and upper bounds.","category":"page"},{"location":"problem/#Inequality-constraint-definition-2","page":"Problem definition","title":"Inequality constraint definition","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To define an inequality constraint f(x) <= 0, where f is a Julia function that accepts a single OrderedDict input, use:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"add_ineq_constraint!(model, f)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"The OrderedDict input to f will be of the same structure, shape and types as the OrderedDict initial solution, lower bounds and upper bounds. The function f can return:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"A number, in which case the constraint will be f(x) <= 0\nA vector or array of numbers, in which case the constraint will be applied element-wise f(x) .<= 0.\nAn arbitrary container or data structure, in which case the output will be vectorized first and the constraint will be applied element-wise on the vectorized output.","category":"page"},{"location":"problem/#Equality-constraint-definition-2","page":"Problem definition","title":"Equality constraint definition","text":"","category":"section"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"To define an inequality constraint f(x) == 0, where f is a Julia function that accepts a single OrderedDict input, use:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"add_eq_constraint!(model, f)","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"The OrderedDict input to f will be of the same structure, shape and types as the OrderedDict initial solution, lower bounds and upper bounds. The function f can return:","category":"page"},{"location":"problem/","page":"Problem definition","title":"Problem definition","text":"A number, in which case the constraint will be f(x) == 0\nA vector or array of numbers, in which case the constraint will be applied element-wise f(x) .== 0.\nAn arbitrary container or data structure, in which case the output will be vectorized first and the constraint will be applied element-wise on the vectorized output.","category":"page"},{"location":"gradients/#Gradients,-Jacobians-and-Hessians","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"","category":"section"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"Nonconvex uses Zygote.jl for automatic differentiation (AD) which in turn uses ChainRules.jl and ChainRulesCore.jl for the adjoint rule definitions of different functions.","category":"page"},{"location":"gradients/#Using-analytic-gradients","page":"Gradients, Jacobians and Hessians","title":"Using analytic gradients","text":"","category":"section"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"To use an analytically derived gradient function analytic_gradient for the function f, you need to define an adjoint rule for the function f using ChainRulesCore.jl as such:","category":"page"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"function ChainRulesCore.rrule(::typeof(f), x::AbstractVector)\n    val = f(x)\n    grad = analytic_gradient(f, x)\n    val, Δ -> (NoTangent(), Δ * grad)\nend","category":"page"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"It's always good practice to check that the rule deifned is correct using ChainRulesTestUtils.jl.","category":"page"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"using ChainRulesTestUtils\ntest_rrule(f, [1.2, 3.6])","category":"page"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"For full details on rrules etc see the ChainRules documentation.","category":"page"},{"location":"gradients/#Using-analytic-Jacobians","page":"Gradients, Jacobians and Hessians","title":"Using analytic Jacobians","text":"","category":"section"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"To use an analytically derived jacobian function analytic_jacobian for the function f, you need to define an adjoint rule for the function f using ChainRulesCore.jl as such:","category":"page"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"function ChainRulesCore.rrule(::typeof(f), x::AbstractVector)\n    val = f(x)\n    jac = analytic_jacobian(f, x)\n    val, Δ -> (NoTangent(), jac' * Δ)\nend","category":"page"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"It's always good practice to check that the rule deifned is correct using ChainRulesTestUtils.jl.","category":"page"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"using ChainRulesTestUtils\ntest_rrule(f, [1.2, 3.6])","category":"page"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"For full details on rrules etc see the ChainRules documentation.","category":"page"},{"location":"gradients/#Using-analytic-Hessians","page":"Gradients, Jacobians and Hessians","title":"Using analytic Hessians","text":"","category":"section"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"There is currently no way to use analytic Hessianas in Nonconvex.jl. If this is a feature you need, please an open an issue and it may be added.","category":"page"},{"location":"gradients/#Using-other-automatic-differentiation-backends","page":"Gradients, Jacobians and Hessians","title":"Using other automatic differentiation backends","text":"","category":"section"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"For specific functions if you want to use ForwardDiff.jl instead of Zygote to compute the gradient or Jacobian, you can define an rrule that uses ForwardDiff to compute the gradient or jacobian, e.g:","category":"page"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"using ChainRulesCore, ForwardDiff\n\nfunction ChainRulesCore.rrule(::typeof(f), x::AbstractVector)\n    val = f(x)\n    grad = ForwardDiff.gradient(f, x)\n    val, Δ -> (NoTangent(), Δ * grad)\nend","category":"page"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"or","category":"page"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"using ChainRulesCore, ForwardDiff\n\nfunction ChainRulesCore.rrule(::typeof(f), x::AbstractVector)\n    val = f(x)\n    jac = ForwardDiff.jacobian(f, x)\n    val, Δ -> (NoTangent(), jac' * Δ)\nend","category":"page"},{"location":"gradients/#AD-limitations-in-Nonconvex","page":"Gradients, Jacobians and Hessians","title":"AD limitations in Nonconvex","text":"","category":"section"},{"location":"gradients/","page":"Gradients, Jacobians and Hessians","title":"Gradients, Jacobians and Hessians","text":"Sparse Jacobians are not yet supported\nAnalytic Hessian functions are not possible to use","category":"page"},{"location":"algorithms/nlopt/#NLopt","page":"NLopt","title":"NLopt","text":"","category":"section"},{"location":"algorithms/nlopt/#Description","page":"NLopt","title":"Description","text":"","category":"section"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"NLopt is an optimization library with a collection of optimization algorithms implemented. Different algorithms have different limitations. To see the limitations of each algorithm, check the algorithms section of the documentation of NLopt. NLopt.jl is the Julia wrapper of NLopt. Nonconvex allows the use of NLopt.jl using the NLoptAlg algorithm struct.","category":"page"},{"location":"algorithms/nlopt/#Quick-start","page":"NLopt","title":"Quick start","text":"","category":"section"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using NLopt.","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"import NLopt\n\nalg = NLoptAlg(:LD_SLSQP)\noptions = NLoptOptions()\nresult = optimize(model, alg, x0, options = options)","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"NLopt is an optional dependency of Nonconvex so you need to load the package to be able to use it.","category":"page"},{"location":"algorithms/nlopt/#Construct-an-instance","page":"NLopt","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"To construct an instance of NLopt's NLOPT_LD_SLSQP algorithm, use:","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"alg = NLoptAlg(:LD_SLSQP)","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"All the algorithms available in NLopt are:","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":":GN_DIRECT\n:GN_DIRECT_L\n:GNL_DIRECT_NOSCAL\n:GN_DIRECT_L_NOSCAL\n:GN_DIRECT_L_RAND_NOSCAL\n:GN_ORIG_DIRECT\n:GN_ORIG_DIRECT_L\n:GN_CRS2_LM\n:G_MLSL_LDS\n:G_MLSL\n:GD_STOGO\n:GD_STOGO_RAND\n:GN_AGS\n:GN_ISRES\n:GN_ESCH\n:LN_COBYLA\n:LN_BOBYQA\n:LN_NEWUOA\n:LN_NEWUOA_BOUND\n:LN_PRAXIS\n:LN_NELDERMEAD\n:LN_SBPLX\n:LD_MMA\n:LD_CCSAQ\n:LD_SLSQP\n:LD_TNEWTON_PRECOND_RESTART\n:LD_TNEWTON_PRECOND\n:LD_TNEWTON_RESTART\n:LD_TNEWTON\n:LD_VAR2\n:LD_VAR1\n:AUGLAG\n:AUGLAG_EQ","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"For a description of the above algorithms, please refer to the algorithms section of NLopt's documentation.","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"Disclaimer:","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"Not all the algorithms have been tested with Nonconvex. So if you try one and it doesn't work, please open an issue.","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"","category":"page"},{"location":"algorithms/nlopt/#Options","page":"NLopt","title":"Options","text":"","category":"section"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"The options keyword argument to the optimize function shown above must be an instance of the NLoptOptions struct when the algorihm is an NLoptAlg. To specify options use keyword arguments in the constructor of NLoptOptions, e.g:","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"options = NLoptOptions(ftol_rel = 1e-4)","category":"page"},{"location":"algorithms/nlopt/","page":"NLopt","title":"NLopt","text":"All the other options that can be set for each algorithm can be found in the algorithms section section of NLopt's documentation.","category":"page"},{"location":"algorithms/surrogate/#Surrogate-assited-Bayesian-optimization","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"","category":"section"},{"location":"algorithms/surrogate/#Description","page":"Surrogate-assited Bayesian optimization","title":"Description","text":"","category":"section"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"Surrogate-assited optimization replaces expensive functions in the objecitve and/or constraints by a surrogate. In Nonconvex, a Gaussian process (GP) from AbstractGPs.jl is used. A certain amount of \"benefit of the doubt\" is given to solutions by minimizing:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"μ(x) - η * σ(x)","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"where μ(x) and σ(x) are the mean and standard deviation of the posterior GP's prediction of the function's value at point x. η is a positive number that resembles how much benefit of the doubt we want to give the solution. A high η means ore exploration and a low η means more exploitation.","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"Similarly, expensive inequality constraints are replaced by:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"μ(x) - η * σ(x) <= 0","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"giving the solution the benefit of the doubt. And each equality constraint is replaced by 2 inequality constraints as such:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"μ(x) - η * σ(x) <= 0 <= μ(x) + η * σ(x)","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"Once the surrogates are formed, they are solved using a sub-optimizer to get the next query point to update the surrogate model. Prior to the optimization loop, initialization is done using a number of points using a Sobol sequence of points.","category":"page"},{"location":"algorithms/surrogate/#Quick-start","page":"Surrogate-assited Bayesian optimization","title":"Quick start","text":"","category":"section"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"f(x) = sqrt(x[2])\ng(x, a, b) = (a*x[1] + b)^3 - x[2]\n\nmodel = Model()\nset_objective!(model, f, flags = [:expensive])\naddvar!(model, [1e-4, 1e-4], [10.0, 10.0])\nadd_ineq_constraint!(model, x -> g(x, 2, 0), flags = [:expensive])\nadd_ineq_constraint!(model, x -> g(x, -1, 1))\n\nalg = BayesOptAlg(IpoptAlg())\noptions = BayesOptOptions(\n    sub_options = IpoptOptions(),\n    maxiter = 50, ftol = 1e-4, ctol = 1e-5,\n)\nr = Nonconvex.optimize(model, alg, [1.234, 2.345], options = options)","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"Note that the flags keyword argument was used when defining the objective and constraints and set to [:expensive]. This is a hint to Nonconvex to use a surrogate in place of these constraint functions.","category":"page"},{"location":"algorithms/surrogate/#Construct-an-instance","page":"Surrogate-assited Bayesian optimization","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"To construct an instance of the surrogate-assisted optimization algorithm, use:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"alg = BayesOptAlg(subsolver)","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"where subsolver is any Nonconvex optimizer to be used to solve the surrogate model.","category":"page"},{"location":"algorithms/surrogate/#Options","page":"Surrogate-assited Bayesian optimization","title":"Options","text":"","category":"section"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"The options keyword argument to the optimize function shown above must be an instance of the BayesOptOptions struct when the algorihm is a BayesOptAlg. The following options can be set using keyword arguments when constructing BayesOptOptions.","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"sub_options: options for the sub-optimizer\nmaxiter: the maximum number of iterations in the Bayesian optimization routine\ninitialize: true by default. If true, the GP will be initialized using a Sobol sequence of query points\nninit: number of initialization points\nctol: feasibility tolerance when accepting a solution\nftol: relative tolerance in the function value\npostoptimize: true by default. If true, a local optimization procedure will be used after the Bayesian optimization is completed.\nkernel: the GP kernel used. All the kernels from KernelFunctions.jl are available.\nnoise: GP observation noise parameter\nstd_multiple: η in the description of the algorithm above.","category":"page"},{"location":"algorithms/surrogate/#Advanced:-manually-constructing-surrogate-functions","page":"Surrogate-assited Bayesian optimization","title":"Advanced: manually constructing surrogate functions","text":"","category":"section"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"Sometimes a function used in the model may need to be replaced by a surrogate but not the entire objective or constraint function. In this case, the surrogate function can be defined explicitly and passed in to the optimize function using the keyword argument surrogates. A surrogate for the function f can be constructed using:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"s1 = Nonconvex.surrogate(f, x0)","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"where x0 is the initial query point. The output of s1(x) will be an interval from [IntervalArithmetic.jl])(https://github.com/JuliaIntervals/IntervalArithmetic.jl) with lo and hi fields, where lo = μ(x) - η * σ(x) and hi = μ(x) + η σ(x). This interval will propagate through the objective function and/or contraint functions outputting an interval or an array of intervals at the end.","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"To define the objective or constraint functions using the manually contructed surrogates, one needs to return the lo field of the output manually at the end of the objective function or inequality constraint function definitions. Equality constraints should also be transformed to a 2-block inequality constraint manually as described above. When manually passing surrogates to the optimize function, the :expensive flag is redundant and will be ignored.","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"Example:","category":"page"},{"location":"algorithms/surrogate/","page":"Surrogate-assited Bayesian optimization","title":"Surrogate-assited Bayesian optimization","text":"x0 = [1.234, 2.345]\ns1 = Nonconvex.surrogate(f, x0)\ns2 = Nonconvex.surrogate(x -> [g(x, 2, 0), g(x, -1, 1)], x0)\n\nmodel = Model()\nset_objective!(model, x -> s1(x).lo)\naddvar!(model, [1e-4, 1e-4], [10.0, 10.0])\nadd_ineq_constraint!(model, x -> getproperty.(s2(x), :lo))\nalg = BayesOptAlg(IpoptAlg())\noptions = BayesOptOptions(\n    sub_options = IpoptOptions(print_level = 0), maxiter = 50, ctol = 1e-4,\n    ninit = 2, initialize = true, postoptimize = false,\n)\nr = Nonconvex.optimize(model, alg, x0, options = options, surrogates = [s1, s2])","category":"page"},{"location":"algorithms/mma/#Method-of-moving-asymptotes-(MMA)","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"","category":"section"},{"location":"algorithms/mma/#Description","page":"Method of moving asymptotes (MMA)","title":"Description","text":"","category":"section"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"There are 2 versions of MMA that are available in Nonconvex.jl:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"The original MMA algorithm from the 1987 paper.\nThe globally convergent MMA (GCMMA) algorithm from the 2002 paper.","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"The MMA algorithm only supports inequality constraints. However, the original algorithm was slightly generalized to handle infinite variable bounds.","category":"page"},{"location":"algorithms/mma/#Quick-start","page":"Method of moving asymptotes (MMA)","title":"Quick start","text":"","category":"section"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"Given a model model and an initial solution x0, the following can be used to optimize the model using MMA.","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"alg = MMA87() # or MMA02()\noptions = MMAOptions()\nresult = optimize(model, alg, x0, options = options, convcriteria = KKTCriteria())","category":"page"},{"location":"algorithms/mma/#Construct-an-instance","page":"Method of moving asymptotes (MMA)","title":"Construct an instance","text":"","category":"section"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"To construct an instance of the original MMA algorithm, use:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"alg = MMA87()","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"or alternatively:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"alg = MMA()","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"To construct an instance of the globally convergent MMA algorithm, use:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"alg = MMA02()","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"or alternatively:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"alg = GCMMA()","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"MMA87\nMMA02","category":"page"},{"location":"algorithms/mma/#Nonconvex.MMA87","page":"Method of moving asymptotes (MMA)","title":"Nonconvex.MMA87","text":"MMA87\n\nThe original method of moving asymptotes (MMA) algorithm from the 1987 paper.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#Nonconvex.MMA02","page":"Method of moving asymptotes (MMA)","title":"Nonconvex.MMA02","text":"MMA02\n\nThe globally convergent method of moving asymptotes (MMA) algorithm from the 2002 paper.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#Options","page":"Method of moving asymptotes (MMA)","title":"Options","text":"","category":"section"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"To specify options for the MMA algorithm, you can construct an instance of MMAOptions and use keyword arguments.","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"MMAOptions","category":"page"},{"location":"algorithms/mma/#Nonconvex.MMAOptions","page":"Method of moving asymptotes (MMA)","title":"Nonconvex.MMAOptions","text":"MMAOptions\n\nA struct that stores all the options of the MMA algorithms. Th following are the fields of MMAOptions:\n\nmaxiter: the maximum number of inner iterations. For MMA87, there is 1 inner iteration per outer iteration.\nouter_maxiter: the maximum number of outer iterations.\nmaxinner: the maximum number of inner iterations per outer iteration of MMA02. Not applicable for MMA87.\ntol: a tolerance struct of type Tolerance.\ns_init: defined in the original MMA02 paper.\ns_incr: defined in the original MMA02 paper.\ns_decr: defined in the original MMA02 paper.\nstore_trace: if true, a trace will be stored.\ndual_options: the options passed to the dual optimizer from Optim.jl.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"The tol option in MMA can be set to an instance of the Tolerance struct:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"Tolerance\nNonconvex.ConvergenceState","category":"page"},{"location":"algorithms/mma/#Nonconvex.Tolerance","page":"Method of moving asymptotes (MMA)","title":"Nonconvex.Tolerance","text":"Tolerance\n\nA struct specifying the different tolerances used to assess the convergence of the algorithms. The following are the fields of Tolerance:\n\nx: the tolerance for Δx in ConvergenceState. x_converged will be true if Δx is less than the x tolerance in Tolerance. This is used to assess convergence when the GenericCriteria is used as the convergence criteria. \nfabs: the tolerance for Δf in ConvergenceState. f_converged will be true if Δf is less than the fabs tolerance in Tolerance. This is used to assess convergence when the GenericCriteria is used as the convergence criteria.\nfrel: the tolerance for relΔf in ConvergenceState. f_converged will be true if relΔf is less than the frel tolerance in Tolerance. This is used to assess convergence when the GenericCriteria is used as the convergence criteria.\nkkt: the KKT tolerance. kkt_converged in ConvergenceState will be true if the kkt_residual is less than the KKT tolerance. And ipopt_converged in ConvergenceState will be true if ipopt_residual is less than the KKT tolerance. This is used to assess convergence when the KKTCriteria, the ScaledKKTCriteria or IpoptCriteria criteria is used as the convergence criteria.\ninfeas: the maximum infeasibility tolerance. infeas_converged in ConvergenceState will be true if the maximum infeasibility is less than the infeasibility tolerance. This is used to assess convergence regardless of the convergence criteria used.\n\nFor more on convergence criteria, see GenericCriteria, KKTCriteria, ScaledKKTCriteria and IpoptCriteria.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#Nonconvex.ConvergenceState","page":"Method of moving asymptotes (MMA)","title":"Nonconvex.ConvergenceState","text":"ConvergenceState\n\nA struct that summarizes the convergence state of a solution. The fields in this struct are:\n\nΔx: the infinity norm of the change in the solution x.\nΔf: the change in the objective value f.\nrelΔf: the ratio of change in the objective value f.\nkkt_residual: the Karush-Kuhn-Tucker (KKT) residual of the solution. If ScaledKKTCriteria is used instead of KKTCriteria, the kkt_residual will be divided by a factor.\nipopt_residual: the modified KKT residual used in the IPOPT solver.\ninfeas: maximum infeasibility amount. This is 0 if the solution is feasible.\nx_converged: true if Δx is less than the x tolerance in MMAOptions.\nfabs_converged: true if Δf is less than the f tolerance in MMAOptions.\nfrel_converged: true if relΔf is less than the f tolerance in MMAOptions.\nkkt_converged: true if the kkt_residual is less than the KKT tolerance in MMAOptions.\nipopt_converged: true if the ipopt_residual is less than the KKT tolerance in MMAOptions.\ninfeas_converged: true if infeas is less than the infeasibility tolerance in MMAOptions.\nf_increased: true if the objective value of the current solution is higher than that of the previous solution.\nconverged: true if the solution satisfies the convergence criteria of choice. See ConvergenceCriteria for more on the different convergence criteria available.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#Convergence-criteria","page":"Method of moving asymptotes (MMA)","title":"Convergence criteria","text":"","category":"section"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"There are 4 convergence criteria available for the MMA algorithm:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"GenericCriteria\nKKTCriteria\nScaledKKTCriteria\nIpoptCriteria","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"Nonconvex.ConvergenceCriteria\nNonconvex.GenericCriteria\nNonconvex.KKTCriteria\nNonconvex.ScaledKKTCriteria\nNonconvex.IpoptCriteria\nNonconvex.assess_convergence!","category":"page"},{"location":"algorithms/mma/#Nonconvex.ConvergenceCriteria","page":"Method of moving asymptotes (MMA)","title":"Nonconvex.ConvergenceCriteria","text":"ConvergenceCriteria\n\nThis an abstract type with 4 subtypes:\n\nGenericCriteria\nKKTCriteria\nScaledKKTCriteria\nIpoptCriteria\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#Nonconvex.GenericCriteria","page":"Method of moving asymptotes (MMA)","title":"Nonconvex.GenericCriteria","text":"GenericCriteria\n\nThis is a generic convergence criteria that uses:\n\nThe maximum change in the solution, Δx,\nThe change in the objective value, Δf, and\nThe change percentage in the objective value, Δf, and\nThe maximum infeasibility infeas.\n\nto assess convergence. More details are given in assess_convergence!.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#Nonconvex.KKTCriteria","page":"Method of moving asymptotes (MMA)","title":"Nonconvex.KKTCriteria","text":"KKTCriteria\n\nThis convergence criteria uses the Karush-Kuhn-Tucker residual and maximum infeasibility to assess convergence. More details are given in assess_convergence!.\n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#Nonconvex.ScaledKKTCriteria","page":"Method of moving asymptotes (MMA)","title":"Nonconvex.ScaledKKTCriteria","text":"ScaledKKTCriteria\n\nThis convergence criteria uses another scaled version of the Karush-Kuhn-Tucker (KKT) residual and maximum infeasibility to assess convergence. In particular if the objective was scaled by a factor m, the KKT residual will be scaled down by a factor max(m, 1/m). This scaling was found to make the convergence criteria less sensitive to scale compared to using the traditional KKT residual. More details are given in assess_convergence!. \n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#Nonconvex.IpoptCriteria","page":"Method of moving asymptotes (MMA)","title":"Nonconvex.IpoptCriteria","text":"IpoptCriteria\n\nThis convergence criteria uses a scaled version of the Karush-Kuhn-Tucker (KKT) residual and maximum infeasibility to assess convergence. This scaled KKT residual is used in the IPOPT nonlinear programming solver as explained in this paper. More details are given in assess_convergence!. \n\n\n\n\n\n","category":"type"},{"location":"algorithms/mma/#Nonconvex.assess_convergence!","page":"Method of moving asymptotes (MMA)","title":"Nonconvex.assess_convergence!","text":"assess_convergence!(\n    solution::Solution,\n    model::AbstractModel,\n    tol::Tolerance,\n    criteria::ConvergenceCriteria,\n)\n\nEvaluates the convergence state solution.convstate given the current solution, solution, the tolerance, tol, and the convergence criteria criteria. solution.convstate.converged is then updated.\n\nIf criteria is an instance of GenericCriteria, converged = (x_converged || f_converged) && infeas_converged. x_converged, f_converged and infeas_converged are explained in Tolerance. If criteria is an instance of KKTCriteria or ScaledKKTCriteria, converged = kkt_converged && infeas_converged. kkt_converged and infeas_converged are explained in Tolerance. If criteria is an instance of IpoptCriteria, converged = ipopt_converged && infeas_converged. ipopt_converged and infeas_converged are explained in Tolerance.\n\n\n\n\n\n","category":"function"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"To specify the convergence criteria, use:","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"converiteria = GenericCriteria()","category":"page"},{"location":"algorithms/mma/","page":"Method of moving asymptotes (MMA)","title":"Method of moving asymptotes (MMA)","text":"replacing GenericCriteria() by KKTCriteria(), ScaledKKTCriteria() or IpoptCriteria().","category":"page"},{"location":"#Nonconvex.jl-Documentation","page":"Getting started","title":"Nonconvex.jl Documentation","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Nonconvex.jl is a Julia package that implements and wraps a number of constrained nonlinear and mixed integer nonlinear programming solvers. There are 4 unique features of Nonconvex.jl compared to similar packages such as JuMP.jl and NLPModels.jl:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Emphasis on a function-based API. Objectives and constraints are normal Julia functions.\nThe use of Zygote.jl for automatic differentiation (AD) of the objective and constraint functions. Specifying analytic gradients is also possible by defining a custom chain rule using ChainRulesCore.jl.\nThe ability to nest algorithms to create more complicated algorithms.\nThe ability to automatically handle structs and different container types in the decision variables by automatically vectorizing and un-vectorizing them in an AD compatible way.","category":"page"},{"location":"#Installing-Nonconvex","page":"Getting started","title":"Installing Nonconvex","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"To install Nonconvex.jl, open a Julia REPL and type ] to enter the package mode. Then run:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"add Nonconvex","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"Alternatively, copy and paste the following code to a Julia REPL:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using Pkg; Pkg.add(\"Nonconvex\")","category":"page"},{"location":"#Loading-Nonconvex","page":"Getting started","title":"Loading Nonconvex","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"To load and start using Nonconvex.jl, run:","category":"page"},{"location":"","page":"Getting started","title":"Getting started","text":"using Nonconvex","category":"page"},{"location":"#Quick-start","page":"Getting started","title":"Quick start","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"f(x) = sqrt(x[2])\ng(x, a, b) = (a*x[1] + b)^3 - x[2]\n\nmodel = Model(f)\naddvar!(model, [0.0, 0.0], [10.0, 10.0])\nadd_ineq_constraint!(model, x -> g(x, 2, 0))\nadd_ineq_constraint!(model, x -> g(x, -1, 1))\n\nalg = IpoptAlg()\noptions = IpoptOptions()\nr = Nonconvex.optimize(model, alg, [1.234, 2.345], options = options)","category":"page"},{"location":"#Table-of-contents","page":"Getting started","title":"Table of contents","text":"","category":"section"},{"location":"","page":"Getting started","title":"Getting started","text":"Pages = [\"problem.md\", \"algorithms/algorithms.md\", \"gradients.md\"]\nDepth = 3","category":"page"},{"location":"algorithms/algorithms/#Algorithms","page":"Overview","title":"Algorithms","text":"","category":"section"},{"location":"algorithms/algorithms/","page":"Overview","title":"Overview","text":"Method of moving asymptotes (MMA)\nIpopt\nNLopt\nAugmented Lagrangian algorithm\nMixed integer nonlinear programming\nMulti-start optimization\nSurrogate-assited Bayesian optimization\nMultiple Trajectory Search","category":"page"}]
}
